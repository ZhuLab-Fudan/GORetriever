# GORetriever

Official code for [GORetriever: Reranking protein-description-based GO candidates by literature-driven deep information retrieval for protein-function-annotation](https://academic.oup.com/bioinformatics/article/40/Supplement_2/ii53/7749084)

## News

- **2025.06.08**  
  We have released large-scale predictions using **GORetriever** on all 420,000 **Swiss-Prot** proteins.
  
  ðŸ‘‰ [Results available here](https://drive.google.com/file/d/1FoKshfeQ_JeHCfRJWaIjjL-GG586Tz1B/view?usp=sharing)
  
  ðŸ‘‰ [For more details](https://github.com/ZhuLab-Fudan/GORetriever/tree/main/result)

- **2025.04.07**  
  Our follow-up work **GOAnnotator: Accurate Protein Function Annotation Using Automatically Retrieved Literature** has been accepted to **ISMB/ECCB 2025**!  
  ðŸ‘‰ Code available at [GOAnnotator GitHub](https://github.com/ZhuLab-Fudan/GOAnnotator)

- **2024.05.30**  
  Our paper on **GORetriever** has been accepted to **ECCB 2024**!

# Requirements

python=3.8

sentence-transformers == 2.2.2

pyserini == 0.10.1.0

pygaggle == 0.0.3.1

faiss-cpu == 1.7.4

numpy == 1.23.5

nltk == 3.8.1

# Inference

Download cross_encoder from https://drive.google.com/file/d/11W51FnM62Z79qGPkuZHRzAv6Bx_L1Mah/view?usp=sharing into folder **cross_model**

```
python predict.py \
  --task [branch] \
  --pro [k] \
  --gpu [n] \
  --file [file]
```

branch: bp, mf, cc

pro: number of retrieved proteins, set k = 3 for MFO and BPO and k = 2 for CCO 

gpu: cuda number, default as 0

file: filename for test set, eg: ./data/test.txt

eg:
```
python predict.py --task bp --pro 3 --gpu 0
```

# Start your own experiments

If you want to start your new experiment, delete the files in folders **test, file, pro_index, go_index**. Otherwise the program will reason based on these pre-existing files.

Rewrite:

- *_pro2go.npy - proteinid -> GO list dictionary in the training data
- pmid2text.npy - Pubmed ID -> title and abstract dictionary for the PubMed article you will use in the training and testing data
- proid2name.npy - proteinid -> protein name dictionary for the PubMed article you will use in the training and testing data
- go_index, pro_index - index built by pyserini

Delete (will be rebuilt after running predict.py):

- *_dev_t5_texts.npy - extracted sentences
- *_retrieval_all.npy
- *_retrieval_pro_3.npy - retrieval result
- *_t5_scores.npy - score cache

# File Structure

â”œâ”€â”€ cross_model - Download

â””â”€â”€â”€â”€â”€â”€ *_PubMedBERT_epoch{}

â””â”€â”€â”€â”€â”€â”€ *_PubMedBERT_epoch1

â”œâ”€â”€ data - training and testing data

â””â”€â”€â”€â”€â”€â”€ golden - evaluate files

â””â”€â”€â”€â”€â”€â”€ *_train.txt - train set

â””â”€â”€â”€â”€â”€â”€ test.txt - test set

â”œâ”€â”€ file

â””â”€â”€â”€â”€â”€â”€ *_pro2go.npy - proteinid -> GO list

â””â”€â”€â”€â”€â”€â”€ pmid2text.npy - Pubmed ID -> title and abstract 

â””â”€â”€â”€â”€â”€â”€ proid2name.npy - proteinid -> protein name

â”œâ”€â”€ test

â””â”€â”€â”€â”€â”€â”€ *_dev_t5_texts.npy - extracted sentences

â””â”€â”€â”€â”€â”€â”€ *_retrieval_all.npy

â””â”€â”€â”€â”€â”€â”€ *_retrieval_pro_3.npy - retrieval result

â””â”€â”€â”€â”€â”€â”€ *_t5_scores.npy - score cache

â”œâ”€â”€ go_index

â”œâ”€â”€ pro_index

â”œâ”€â”€ result - final result

â”œâ”€â”€ predict.py

â””â”€â”€ data_preprocess.py
